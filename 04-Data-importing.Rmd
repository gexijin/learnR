#  Importing data and managing files

Learning objectives:

- Create projects in Rstudio
- Understand the proper steps to import data
- Get introduced to data transformation using dplyr



## Project-oriented workflow

When embarking on your data journey, it's smart to create a separate folder for each project that contains all related files. This approach is especially handy for research projects. Each of these folders, known in RStudio as a **Project**. For example, you can create a project for each chapter in this book. Projects are self-contained universe, making your code robust and portable across different computers and directories.

>
If the first line of your R script is
>
>
setwd("C:\\Users\\jenny\\path\\that\\only\\I\\have")
>
>
I will come into your office and SET YOUR COMPUTER ON FIRE 
>
>
---\@JennyBryan on Twitter

Here's a helpful video guiding you through creating a project and importing data in RStudio.

<iframe width="851" height="638" src="https://www.youtube.com/embed/Hm8Fc5HbXXQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

And down here the process is illustrated in detail.

![Animated GIF for creating project and import data.](https://github.com/gexijin/learnR/raw/master/images/dataImport.gif)


###	Create a project in a new folder 
First, let's set up a new project. In RStudio, go to **File->New project->New Directory->Empty Project**. Then choose the directory's house on your hard drive where the project will be created. For instance, create a directory named “Chapter4” under "D:\\RBook". Rstudio will then whip up a project file “Chapter4.Rproj”, which contains essential information such as scripts files and working folders. Project file can be saved and reopened later from **File->Open** or just simply by double-clicking on it in Windows. This folder becomes your **working folder**, a default folder for reading files, writing outputs, etc. Now you get everything ready to go on a particular assignment or research project. 

Advanced users should consider create a project using version control for an extra layer of magic, so that all versions of your code is backup and easily shared by [GitHub](https://github.com/). Check out [Happy Git and GitHub for the useR](https://happygitwithr.com/) by Jenny Bryan for more enchantments. 

###	Create a script file (and Comment, Please!) 
Once you have set up a new project, the first step is to start a new script file by clicking the **File +**  button or go to **File->New file** and choose **R script file**. By default, the script file is called Untitled1.R. Rstudio awaits you to rename it at the first time you hit “Save” button. 

Start your R script by adding comments with background information. Comments starting with “#” are ignored by R when running, but they are helpful for your future self and others to understand the code. We re-cycle and re-use our codes over and over, so it is vital to add information about the background and purpose of your code segments. Figure \@ref(fig:9-1) shows a recommended workflow for starting your script. Click "Save" button and name your file something like "Data Import.R". 

Efficient coding in R requires a systematic approach to writing and executing scripts, also, **write your scripts while saving your project files**. 
In RStudio, executing code is straightforward. If you click on the **Run** button, Rstudio runs the current line of code where your cursor is located. If you select multiple lines and hit **Run**, you can run them all at once. You can even jump back and forth when editing and rerunning sections of code. But remember that you are operating on the data objects sequentially. It is crucial to maintain awareness of this order. Run the reset line **rm(list=ls())** if you want to get a fresh start. This command lists and then deletes all data objects from R’s brain. Don't forget to save everything once a while by hitting the **Save** button on the main icon bar! Even though Rstudio saves your scripts every 5 seconds, unforeseen crashes may occur. 

As you develop your coding skills, following these above guidelines can make you more efficient when you start a R script.
   

(ref:9-1) A recommended workflow for starting a project in Rstudio: commenting, resetting, checking the working folder.

```{r 9-1, echo=FALSE, out.width='80%', fig.cap='(ref:9-1)', fig.align='center'}
knitr::include_graphics("images/img0901_rstudio.png")
```

###	Copy data files to the new directory
This step is a little field trip outside RStudio on Windows or Mac interface. Download the the necessary files, like heartatk4R.txt file from [here](https://raw.githubusercontent.com/gexijin/learnR/master/datasets/heartatk4R.txt). It is a tab-delimited text file, meaning its columns are separated by tabs. We need to get some context about the data and how it is collected. Knowing what each column represents is crucial, like decoding a treasure map.

 **File unzipping, conversion, and context.**
If your data is compressed, use 7-zip, WinRAR, Winzip, or gzip to unzip it. Check if your file is text file (CSV, txt, …) or Binary file (XLS, XLSX, …), and convert binary to text file using corresponding application. Remember, CSV files separate the columns by commas, while tab-delimited files use the invisible character tab, $\t$. 

 **Checking the file with text editor and Excel.** 
Before reading files into R, we often need to open the files to take a look. Plain text files only contain text without any formatting, links, and images. The file names can be “poems.txt”, “poems.tex”, “students.csv”,  or just “data” without extension. I often save my R scripts as text files with names like “code_1-22-2017.R”.

To peek inside the data, avoid the limited (and amateur) editors like Notepad or WordPad , and definitely don’t invite Microsoft Word for this purpose! I strongly recommend that you install a powerful text editor such as NotePad++ (https://notepad-plus-plus.org/), or TextPad (https://www.textpad.com/).  If you are a Mac user, try TextMate, TextWrangler etc. I use NotePad++ almost every day to look into data, and also write R programs, as it can highlight R commands based on R syntax. I even use a tool called NppToR (https://sourceforge.net/projects/npptor/) to send R commands from NotePad++ directly to R, and I love it! Regardless of the extensions(.txt, .tex, .csv, etc.) in file names, all **plain text files** can be opened by these text editors. 

Excel can also be a handy sidekick. You can import text files, regardless of file names, to Microsoft Excel, which can properly parse your file into columns if the correct delimiter is specified. Comma separated values (CSV) files can also be conveniently opened by Excel. 

Rstudio favors CSV files and tab-delimited text files. Other types of files such as Excel, .xls, or .xlsx files are often needed to be saved as CSV files for smoother journeys.

### Import data files
In Rstudio, click **File->Import Dataset->From text(readr)…**, and find the file on your hard drive. You should change the **Delimiter** to “tab” for a correct read. The preview shows that the data is correctly parsed into multiple columns. You can rename your data object for ease. For instance, change the default “heartatk4R” to simple **“df”** on the lower left of the import interface. 

We need to check each of the columns to ensure the data types match their intended purpose. 

The first column is just patient id number runs from 1 to 12844. It will not be useful in our analysis. The numbers in DIAGNOSIS, DRG, and DIED are integers but they actually **code for certain categories**. They are not measurements. It does not make sense, for example, to add them or average them. Most of the times, there is no particular order. The same is true for SEX. 
So in this dialog interface, DIAGNOSIS, DRG, and DIED should be changed from **"double"** to **"character"**. 
As shown in Figure \@ref(fig:9-2), you can click on the automatically guessed data type under each of the column names. By selecting “character” from the drop down list, you can successfully format the column as character.

On the other hand, LOS (length of stay in days) and AGE should be numbers. But because 10 is presented as "0010", these columns are automatically recognized as characters. We have to force R to read these columns as integers by clicking on the column title and select **integer**. So that we change LOS and AGE from **"character"** to **"integer"**. 

Rstudio, like an awesome apprentice, actually helped you generating these 3 lines of code:

```{r warning=FALSE, echo=FALSE, results='hide', message=FALSE}
library(readr)
df <- read_delim("datasets/heartatk4R.txt", 
  "\t", escape_double = FALSE, col_types = cols(AGE = col_integer(), 
  DIAGNOSIS = col_character(), DIED = col_character(), 
  DRG = col_character(), LOS = col_integer()), 
  trim_ws = TRUE)
```

```{r eval=FALSE, results='hide', message=FALSE}
library(readr)
df <- read_delim("datasets/heartatk4R.txt", 
  "\t", escape_double = FALSE, col_types = cols(AGE = col_integer(), 
  DIAGNOSIS = col_character(), DIED = col_character(), 
  DRG = col_character(), LOS = col_integer()), 
  trim_ws = TRUE)
View(df)
```

Before you click on the **Import** button, I highly recommend that you select all the codes and copy them to the script file for future use. If you already have a script window open, you can directly paste the code into a script window after clicking **Import**. If not, create one by clicking the **File +** icon on the top left, then copy and paste these codes to your script file. You will need them if you want to re-run the analysis without going through the above steps. You can view the data which now appears as a spreadsheet after importing. It can be sorted by clicking on the column names. This spreadsheet can be closed. To reopen, click on 'df' object in your workspace, which is the data frame named for the imported file. You data is now available as **df**. 
   
(ref:9-2) Adjusting data types while importing data into Rstudio.

```{r 9-2, echo=FALSE, fig.cap='(ref:9-2)', fig.align='center'}
knitr::include_graphics("images/img0902m_datatype.png")
```   


###  Check and convert data types

R usually guesses column types correctly, but you always need to verify using the str() command. If the types aren't quite right, you can enforce data type conversion using functions like as.numeric, as.factor, or as.character.

```{r}
str(df)  # Structure and data types for each column
```


Categorical values can be reformatted as **factors** using as.factor() function. Here use ```df$SEX``` to refer to the SEX column of the data frame df:
```{r}
df$DIAGNOSIS <- as.factor(df$DIAGNOSIS)  # Convert this column to a factor
df$SEX <- as.factor(df$SEX)
df$DRG <- as.factor(df$DRG)
df$DIED <- as.factor(df$DIED)
```

Factors are very similar to character vectors but with superpowers of defined levels and integer storage.

```{r}
nlevels(df$DIAGNOSIS)  # Explore the number of levels
levels(df$DIAGNOSIS)   # Display the levels
```
Note  "41001" is the **reference level** for this factor and it is coded as 1. The reference level for factors is important when we interpret results from regression, as effects are represented relative to the reference level. The reference level is defined automatically based on the order of the factors appear in the dataset. Sometimes we need to change the reference level:

```{r}
df$DIAGNOSIS <- relevel(df$DIAGNOSIS, "41091")
levels(df$DIAGNOSIS)
```


```{r}
str(df)  # Recheck the structure
summary(df)   # Summarize the data for a quick overview
```
The summary( ) function is very useful to get basic information about data frame. It distinguishes numeric columns by statistics like mean and median, and factors by frequency counts. This reassured us that the data types are correctly recognized. It also shows missing values in CHARGES. 
Did some people get free treatment for heart attack? Maybe not. Missing does not mean zero. Maybe the data was not entered for some patients.  

Just a reminder: Except enforcing data type conversion by as.factor, as.numeric and so on, we can also reformat the columns before clicking **Import** as we described in 4.2.4.

### Close a project when you are done
Think of RStudio as a friendly but slightly clingy companion. So, when you're done with a project, it's necessary to say goodbye politely by navigating to **File $\rightarrow$Close Project**. If not, *RStudio assumes that you will be continue working on the same project*; even after your close Rstudio, the same project and files will be open the next time you start Rstudio. It is convenient, most of times. But I've seen some students' Rstudio environment cluttered with all the things they have been doing for an entire semester. This is not only confusing, but could also lead to errors.  For this class, consider starting a fresh project for each chapter.

To open a project, use **File $\rightarrow$Open Project** and then navigate to the project. Alternatively you can double-click on the project file (like "Chapter4.Rproj") from your file explorer in Windows or Mac. When a project file is loaded, the entire computing environment is kindly set for you, including the working directory and any script files you left open. If a script file is not open, you can easily access it by clicking on it from the **Files** tab in the lower right window. 


## Read files directly using read.table

As you get more experience with R programming, you'll find multiple ways to import data, beyond the friendly Import Dataset feature in RStudio.

Here's the code to bring in our heart attack dataset, ensuring it's in the current working directory. To set working directory from the Rstudio main menu, go to Session -> Set Working Directory.

```{r results='hide'}
rm(list = ls())  # Erase all objects in memory
getwd()  # Display the current working directory
df <- read.table("datasets/heartatk4R.txt", sep="\t", header = TRUE)
head(df)  # Peek at the first few rows
# Convert several columns to factors
df$DRG <- as.factor(df$DRG)
df$DIED <- as.factor(df$DIED)
df$DIAGNOSIS <- as.factor(df$DIAGNOSIS)
df$SEX <- as.factor(df$SEX)
str(df)  # Check the data types of columns
summary(df)  # Get a summary overview of the dataset
```

Alternatively, for the digital explorer, try this: 
```{r eval = FALSE}
URL <- "https://raw.githubusercontent.com/gexijin/learnR/master/datasets/heartatk4R.txt"
df <- read.table(URL, 
                 header = TRUE, 
                 sep = "\t", 
                 colClasses = c("character", "factor", "factor", "factor", 
                               "factor", "numeric", "numeric", "numeric"))
```

This way, you’re directly importing data from the internet using the URL and defining column data types right off the bat.


## General procedure to read data into R:
1.	Unzip files using 7-zip, WinRAR, Winzip, gzip, etc, if data is compressed. Any of these will work. 
2.	Identify if it's a text file (CSV, txt, …) or Binary file (XLS, XLSX, …). Convert binary to text file using corresponding application. Comma separated values (CSV) files use comma to separate the columns. While tab-delimited text files(txt) use the tab, or the invisible character $\t$.  
3.	Preview the file using a text editor like TexPad or NotePad++. 
4.	Check for rows and columns and their names. Use **row.names = 1, header = T** if needed.
5.	Identify the delimiters between columns (space, comma, tab…). Use **sep = “$\t$”** for tabs.
6.	Missing values?  Look for NA, na, NULL, blank, NaN, and 0. Specify them using **missingstring = **.
7.	Open as text file in Excel, choosing the appropriate delimiter while importing, or using the **Text to Column** under 'Data' in Excel. Beware of the annoying automatic conversion in Excel (e.g., “OCT4” to “4-OCT”).  Edit column names by removing spaces, or shorten them for easy of reference in R. And save as CSV.
9.	Read data using read.table( ),  or read.csv( ). For example,
 ```x <- read.table(“somefile.txt”, sep = “\t”, header = TRUE, missingstring = “NA”)```
10.	Double check data types with **str(x)**, make sure each column is recognized correctly as **“character”**, **“factor”** and **“numeric”**. Pay special attention to numbers that are actually IDs or categories; as they need specific treatments.
IDs (i.e. student IDs) should be treated as character.  For example, ```x$ids <- as.character(x$ids)```,  here x is the data frame and ids is the column name. Codes for some discrete categories (1, 2, 3, representing treatment 1, treatment 2 and treatment 3), need to be reformatted as **factors**. This could be done with something like ```x$treatment <- as.factor(x$treatment)```. 

Check out cheat sheets for a quick refresher, which summarize many R functions and are available here: [https://www.rstudio.com/resources/cheatsheets/](https://www.rstudio.com/resources/cheatsheets/). Remember, it is important to understand the different types of R objects: **scalars, vectors, data frames, matrix, and lists**. 


>
```{exercise} 

>
Create a project for chapter 4 if you haven’t yet. Download the tab-delimited text file *pulse.txt* from [this link] (http://statland.org/R/R/pulse.txt). Import pulse.txt into R using two methods: R menu (Show the process with necessary screenshots) and R script.     
a. Rename the file as *chapter4Pulse*.         
b. Change the class of ActivityL from double to integer.       
c. After importing *pulse.txt* into R, convert the class of Sex from charater to factor using R code. Don't forget using class() function to check your answer.
```

>
```{exercise}

>
Type the data from Table \@ref(tab:9-01) in Excel and save as both CSV file and tab-delimited text file. Start a new Rstudio project as previously described. Copy the files to the new folder, and import the CSV file to Rstudio. Create a script file which includes the command for preparing the workspace (rm(list = ls()) and getwd()), the generated R code when importing the CSV file (similar to those shown in Figure \@ref(fig:9-2)), and the code to convert data types (Age, BloodPressure and	Weight should be numeric, LastName should be character, and HeartAttack should be factor). Name the data set as *patients*. Submit your R script, the data structure of *patients*,  and the output from **head(patients)**. 
```
>
```{r echo=FALSE, results='hide'}
LastName <- c("Smith", "Bird", "Wilson")
Age <- c("19", "55", "23")
Sex <- c("M", "F", "M")
BloodPressure <- c("100", "86", "200")
Weight <- c("130.2", "300", "212.7")
HeartAttack <- c("1", "0", "0")
dat <- data.frame(LastName,	Age, Sex, BloodPressure, Weight, HeartAttack)
```

```{r 9-01, echo=FALSE}
knitr::kable(
  data.frame(dat),
  booktabs = TRUE,
  caption = 'An example of a multivariate dataset'
)
```


## Enter data manually
There are many different ways to invite data into R. You can enter data manually (see below), or semi-manually (see below),  or read data from a local file or a file on the internet. R can also retrieve data from databases, local or remote. The most important thing is to read data set **correctly** into R. A dataset misread by R is like a mischievous elf - it will never be analyzed or visualized correctly.

```{r 9-0, echo=FALSE, out.width='50%', fig.align='center'}
knitr::include_graphics("images/img0900_note.png")
```


```{r}
x <- c(2.1, 3.1, 3.2, 5.4)
sum(x)
A <- matrix(
  c(2, 4, 3, 1, 5, 7),  # Data elements 
  nrow = 2,             # Number of rows 
  ncol = 3)             # Number of columns                     
A                       # Display the matrix
```

And for a twist, you can even use the scan() function to manually input values, or simply copy and paste a column of numbers from Excel.
```{r}
x <- scan()  # Manually enter values from keyboard, separated by Return key. End by empty line. 
2.1
3.1
4.1

```


## Data manipulation in a data frame 
Let's take our heart attack dataset *df* and give it a spin. Here's a golden rule: always type commands in the Script window, not directly into the Console. And Make it a habit to save your work frequently – there's nothing sadder than losing data! 

Now imagine we want to sort our patients by age:
```{r}
df2 <- df[order(df$AGE), ]  # Sort by ascending order by AGE
```

**Global Environment** window is like a digital pantry, storing the names and sizes of all the variables or objects in the computer memory. R programming is essentially a culinary art of creating and modifying these objects with crystal-clear, step-by-step instructions. And yes, you can also sort the data by clicking on the column names in spreadsheet view in the Global Environment, just like in Excel.

Speaking of Excel, you can add a new column with computed results in R too:
```{r}
df2$pdc <- df2$CHARGES / df2$LOS
```

Here we created a new column pdc to represent per day cost. 
You can also create a column to represent age groups using the *floor* function which just returns the integer part.
```{r}
df2$ag <- floor(df2$AGE / 10) * 10
```

You can now do nifty things like this:
```{r }
boxplot(df2$CHARGES ~ df2$ag) # Boxplot of charges by age groups
```

Each box represents an age group's hospital stay during the post-heart attack. Older patients tend to stay longer in the hospital after heart attack. 

For a more focused analysis, extract a specific subset:
```{r}
df3 <- subset(df2, SEX == "F")  #  Only females. “==” is for comparison and “=” is for assign value.
df4 <- subset(df3, AGE > 80)  # Only people older than 80
summary(df4)   # What's the story here?
```
Remember, it's best to avoid attaching data during such manipulations.

## Data transformation using the dplyr
Following the same style of ggplot, the dplyr package, a part of the [Tidyverse](https://www.tidyverse.org/), makes data transformation more intuitive.

First let's install the dplyr package. 
```{r eval=FALSE}
install.packages("dplyr")
```

With dplyr, data transformation becomes more of a dance than a chore.
```{r warning=FALSE, message=FALSE}
library(dplyr)

df2 <- df %>%  # Pipe operator; data is send to the next step
  arrange(AGE) # Sort AGE in ascending order; desc(AGE) for descending order
head(df2)

df2 <- df2 %>% 
  mutate( pdc = CHARGES / LOS) # New column for per day cost
head(df2)

df2 <- df2 %>% 
  mutate( ag = floor(AGE/10) * 10) # New column for age groups
head(df2)

df3 <- df %>% 
  filter(SEX == "F", AGE > 80) # Filtering for females over 80
head(df3)
```

The real power and efficiency of dplyr comes when you connect the pipes to do data transformation in multiple steps, like a chain of dominoes.
```{r}
df2 <- df %>% 
  arrange(AGE) %>%
  mutate( pdc = CHARGES / LOS) %>%   
  mutate( ag = floor(AGE/10) * 10) %>%
  filter(SEX == "F", AGE > 80)
head(df2)
```

**arrange, mutate, filter** are called **action verbs** in the dplyr realm. For more action verbs, check out the dplyr cheat sheet from the Rstudio main menu: *Help $\rightarrow$ Cheatsheets $\rightarrow$ R Markdown Cheat Sheet.*  It is also available online at [dplyr cheat Sheet](https://www.rstudio.com/resources/cheatsheets/#dplyr). 

So there you have it! With tools like dplyr, you're transforming data analysis into a harmonious symphony of insights. Enjoy the rhythm of data exploration!